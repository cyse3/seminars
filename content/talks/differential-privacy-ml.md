---
title: "Is Differential Privacy a Silver Bullet for Machine Learning?"
date: 2022-03-16
time: 3PM
presenter: "nicolas-papernot"
youtube: "cy0KcDCHX34"
zoom-link: "https://newcastleuniversity.zoom.us/j/83414117847?pwd%3Dd01RbWdsWWVLc2pZSHpFZjVBS1IzQT09"
zoom-id: "834 1411 7847"
zoom-password: "740564"
---

Some machine learning applications involve training data that is sensitive, such as the medical histories of patients in a clinical trial. A model may inadvertently and implicitly store some of its training data; careful analysis of the model may therefore reveal sensitive information. To address this problem, algorithms for private machine learning have been proposed. In this talk, we first show that training neural networks with rigorous privacy guarantees like differential privacy requires rethinking their architectures with the goals of privacy-preserving gradient descent in mind. Second, we explore how private aggregation surfaces the synergies between privacy and generalization in machine learning. Third, we present recent work towards a form of collaborative machine learning that is both privacy-preserving in the sense of differential privacy, and confidentiality-preserving in the sense of the cryptographic community. We motivate the need for this new approach by showing how existing paradigms like federated learning fail to preserve privacy in these settings.
