---
title: "An Unreliable Foundation: Security & Privacy of Large Scale Machine Learning"
date: 2021-09-22
time: 2PM
presenter: "nicholas-carlini"
youtube: "FRWdpVLTmmw"
zoom-link: "https://newcastleuniversity.zoom.us/j/87852741099?pwd%3Dc1FhRk5EdkJVa0RzbkUxalhZbURLQT09"
zoom-id: "878 5274 1099"
zoom-password: "782722"
---

Instead of training neural networks to solve any one particular task, it is now common to train neural networks to behave as a “foundation” upon which future models can be built. Because these models train on unlabeled and uncurated datasets, their objective functions are necessarily underspecified and not easily controlled.


In this talk I argue that while training underspecified models at scale may benefit accuracy, it comes at a cost to security and privacy. Compared to their supervised counterparts, large underspecified models are more easily attacked by adversaries. As evidence, I give three case studies where larger models are less reliable across three different problem setups. Addressing these challenges will require new solutions than those that have been studied in the past.
